{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM building, learning and predicting #\n",
    "\n",
    "Create a HMM using fair and loaded dices. Create your model to predict an unknown model (the provided one).\n",
    "The provided model is:\n",
    "$$\n",
    "Grammar: \\\\\n",
    "Begin \\rightarrow f1 | l1 \\\\\n",
    "l1 \\rightarrow l2 \\\\\n",
    "l2 \\rightarrow l2 | l3 | f1 \\\\\n",
    "l3 \\rightarrow l3 | f1 |end \\\\ \n",
    "f1 \\rightarrow f1 | l1 |end \\\\\n",
    "\\\\\n",
    "labels: \\\\ \n",
    "l1, l2, l3 \\rightarrow loaded-dice (L)\\\\ \n",
    "f1 \\rightarrow fair-die (F)\n",
    "$$\n",
    "\n",
    "1. Write your onw HMM model and use the provided training and the testing sequences (created with with the **base_HMM **)\n",
    "2. Implement Forward and Backward algorithms and train the model using Expectation Maximization: <br>\n",
    "   2.1 Train your model using state labels (Fair/Loaded) and observed sequence (Heads and Tails) <br>\n",
    "   2.2 Train your model using only the observed sequence (Heads/Tails) **[This is optional]** <br>\n",
    "3. Implement a Viterbi and Posterior decoding and compare the predicted labels with the observed labels (Testing), evaluate the Coen's k-score, and other measure of accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class base_HMM:\n",
    "- string_2_vec: returns a two columns (head/tail) matrix with the lenght of the sequence as number of rows. If the i-th sequence element is H/T, the i-th row of the matrix has a 1 in the correspondig column\n",
    "- forward function: this function generates the forward matrix given x and y string\n",
    "- backward function: this function generates the backward matrix given x and y string\n",
    "- viterbi function: returns the hidden path given the emission states (decoding problem)\n",
    "- A posteriori function\n",
    "- Baum Welch\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "class base_HMM:\n",
    "    def __init__(self, states, state_labels, symbols, a=[], e =[]):\n",
    "        ''' HMM(states, symbols, a=None, e = None)\n",
    "        we assume that first name is begin and last name is end state\n",
    "        we assume to order the state names and the symbols so that a and e are numpy matrices\n",
    "        '''\n",
    "        self.states = states\n",
    "        self.n_states = len(states)\n",
    "        self.labels = state_labels\n",
    "        self.n_lab = len(state_labels)\n",
    "        self.symbols = symbols\n",
    "        self.n_symb = len(symbols)\n",
    "        self.a = a\n",
    "        self.e = e\n",
    "        self.eps=0.00001 #for overflow problems (denom / exp / log etc)\n",
    "        if self.a != []:\n",
    "            self.allowed_tr = np.where(self.a >0,1.0,0)  \n",
    "        else:\n",
    "            self.allowed_tr =  []\n",
    "            \n",
    "    def string_2_vec(self, s, alph):\n",
    "        vector = [[0 if char != letter else 1 for char in alph] for letter in s]\n",
    "        return np.array(vector)\n",
    "\n",
    "\n",
    "    def init_prob(self, mode=\"random\",epsilon =10**(-10)):\n",
    "        ''' init_prob(mode=\"random\"/ \"uniform\" '''\n",
    "        if mode == \"random\":\n",
    "            a = np.random.uniform(1,100,(self.n_states,self.n_states))\n",
    "            e = np.random.uniform(1,100,(self.n_states,self.n_symb))\n",
    "        else:\n",
    "            a = np.ones((self.n_states,self.n_states))\n",
    "            e = np.ones((self.n_states,self.n_symb))\n",
    "        if self.allowed_tr != []:\n",
    "            a = a * self.allowed_tr\n",
    "        a[:,0] = 0 # no transition to begnin\n",
    "        a[0][-1] = 0 # no trnasition begin to end\n",
    "        a[-1] = 0 # no transitions from end to other states\n",
    "        self.a = a / (a.sum(axis=1)[:,np.newaxis] + epsilon) # normalize\n",
    "        e[0] = 0 # no emissions in begin\n",
    "        e[-1] = 0 # no emissions in end\n",
    "        self.e = e / (e.sum(axis=1)[:,np.newaxis]+ epsilon) # normalize\n",
    "        \n",
    "    def forward(self, x_seq, y_seq):\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        y = y_seq \n",
    "        N = len(x)\n",
    "        F = np.zeros((N+2,self.n_states))        \n",
    "        scale = np.zeros(N+2)\n",
    "        # forward initialization\n",
    "        F[0][0] = 1.0\n",
    "        scale[0] = 1.0\n",
    "        # forward loop\n",
    "        for i in range(1,N+1):\n",
    "            for s in range(self.n_states):\n",
    "                if self.labels[s] == y[i-1]:\n",
    "                    #print(s, self.labels[s], y[i-1])\n",
    "                    for t in range(self.n_states):\n",
    "                        F[i][s] += self.a[t,s]*F[i-1][t]\n",
    "                    F[i][s] *= np.dot(self.e[s],x[i-1])\n",
    "            scale[i] = np.sum(F[i])\n",
    "            F[i]/=scale[i]\n",
    "        s = self.n_states -1  # end state\n",
    "        i = N + 1\n",
    "        for t in range(self.n_states):\n",
    "            F[i][s] += self.a[t,s]*F[i-1][t]\n",
    "        scale[i] = np.sum(F[i])\n",
    "        F[i]/=scale[i]\n",
    "        return F\n",
    "\n",
    "    \n",
    "    def backward(self, x_seq, y_seq): #faccio la stessa cosa del forward ma parto dalla fine\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        y = y_seq \n",
    "        N = len(x)\n",
    "        bkw = np.zeros((N+2,self.n_states))        \n",
    "        scale = np.zeros(N+2)\n",
    "        # backward initialization\n",
    "        bkw[-1][-1] = 1.0\n",
    "        scale[0] = 1.0\n",
    "        \n",
    "        for s in range (self.n_states):\n",
    "            if self.labels[s] == y[-1]:\n",
    "                #print(s, self.labels[s], y[-1])\n",
    "                bkw[-2][s] = self.a[s, -1]\n",
    "                scale[-2] += self.a[s, -1]\n",
    "        bkw[-2]/=scale[-2]\n",
    "        \n",
    "        for i in range(N-1, 0, -1):\n",
    "            #print(i)\n",
    "            for s in range (self.n_states):\n",
    "                if self.labels[s] == y[i-1]:\n",
    "                    #print(s, self.labels[s], y[i])\n",
    "                    for t in range(self.n_states):\n",
    "                        #print(bkw[i-1][s])\n",
    "                        bkw[i][s] += self.a[s,t]*bkw[i+1][t]*np.dot(self.e[t],x[i])\n",
    "                    scale[i] = np.sum(bkw[i])\n",
    "            bkw[i]/=scale[i]  \n",
    "   \n",
    "    #filling begin state\n",
    "       \n",
    "        for t in range(self.n_states):\n",
    "            bkw[0][0] += self.a[0,t]*bkw[i+1][t]*np.dot(self.e[t],x[i])\n",
    "        \n",
    "        scale[0] = np.sum(bkw[0])\n",
    "        bkw[0]/=scale[0]\n",
    "        \n",
    "        return bkw\n",
    "    \n",
    "   ### ### ### ### ### ### ###\n",
    "    \n",
    "#FINDING THE PATH\n",
    " \n",
    "#these two functions return the hidden path: pie_labels\n",
    "    \n",
    "    def viterbi(self, x_seq):\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        #y = y_seq \n",
    "        N = len(x)\n",
    "        T=N+2\n",
    "        \n",
    "        p_tr = np.zeros((N,self.n_states))\n",
    "        pie_star=np.zeros(N)\n",
    "        #viterbi initialization\n",
    "        W = np.zeros((T,self.n_states))\n",
    "        scale = np.zeros(T)\n",
    "        W[0][0] = 1.0\n",
    "        scale[0] = 1.0\n",
    "        # Viterbi Recurrence\n",
    "        \n",
    "        for i in range(0,N):\n",
    "            for s in range(self.n_states):\n",
    "                maximum= max([self.a[k,s]*W[i][k] for k in range(self.n_states)])\n",
    "                W[i+1][s] = maximum*np.dot(self.e[s],x[i])\n",
    "                #print(W[i+1][s])\n",
    "                p_tr[i][s] = np.argmax([self.a[k,s]*W[i][k] for k in range(self.n_states)])\n",
    "            scale[i+1] = np.sum(W[i+1])\n",
    "            W[i+1]/=scale[i+1] \n",
    "        #Viterbi Termination\n",
    "        q=self.n_states-1\n",
    "        W[T-1][q] = max([self.a[k,q]*W[T-1][k] for k in range(self.n_states)])\n",
    "        pie_star[N-1]=np.argmax([self.a[k,q]*W[N][k] for k in range(self.n_states)])\n",
    "        #Traceback\n",
    "        for i in range(N-1, 0, -1):\n",
    "            #print(i)\n",
    "            pie_star[i-1] = p_tr[i][int(pie_star[i])]\n",
    "        pie_label=[]\n",
    "        for r in range(N):\n",
    "            pie_label.append(self.labels[int(pie_star[r])])\n",
    "        return W, pie_label\n",
    "        #return pie_label\n",
    "    \n",
    "    def posteriori(self, x_seq, y_seq):\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        N = len(x)\n",
    "        alpha = self.forward(x_seq, y_seq)\n",
    "        beta = self.backward(x_seq, y_seq)\n",
    "        pie_star = [np.argmax([alpha[i+1][k] * beta[i+1][k] for k in range(self.n_states)]) for i in range(N)]\n",
    "        pie_label=[]\n",
    "        for r in range(N):\n",
    "            pie_label.append(self.labels[int(pie_star[r])])\n",
    "        return pie_star, pie_label\n",
    "        #return pie_label\n",
    "    \n",
    "    ### ### ### ### ### ### ### ### \n",
    "    \n",
    "    def baum_welch(self,x_seq, y_seq, n_iter=1):\n",
    "       \n",
    "        x = self.string_2_vec(x_seq, self.symbols) \n",
    "        xseq = np.zeros((len(x_seq),1))\n",
    "        #inizializzo a random a (transiz) ed e (emiss) e normalizzo\n",
    "        self.a = np.random.rand(self.n_states, self.n_states)\n",
    "        self.e = np.random.rand(self.n_states, self.n_symb)\n",
    "        for i in range(self.n_states):\n",
    "            self.a[i]/=np.sum(self.a[i])\n",
    "            self.e[i]/=np.sum(self.e[i])\n",
    "    \n",
    "        T = len(x)  \n",
    "        N = T+2\n",
    "        # loop\n",
    "        csi = np.zeros((self.n_states, self.n_states))\n",
    "        gamma = np.zeros((self.n_states, self.n_symb))\n",
    "        a_star = np.zeros((self.n_states, self.n_states))\n",
    "        b_star = np.zeros((self.n_states, self.n_symb))\n",
    "        for i in range(n_iter): #n iter è il tempo che passa\n",
    "            \n",
    "            #build forward and backward matrix\n",
    "            Fwd = self.forward(x_seq, y_seq)  \n",
    "            Bwd = self.backward(x_seq, y_seq)\n",
    "            \n",
    "            #compute b star \n",
    "            for r in range(self.n_states):   \n",
    "                for p in range(len(self.symbols)):\n",
    "                    b_star[r][p] = sum([Fwd[j+1][r]*Bwd[j+1][r] for j in range(T) if x[j,p]==1])      \n",
    "      \n",
    "            #compute a star\n",
    "            for k in range(self.n_states):\n",
    "                for l in range(self.n_states):\n",
    "                    a_star[k][l] = sum([Fwd[j][k]*self.a[k][l]*np.dot(self.e[l],x[j])*Bwd[j+1][l] for j in range(T)])\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.a=a_star\n",
    "        self.e=b_star\n",
    "        \n",
    "        return self.a, self.e\n",
    "        \n",
    "\n",
    "    ### ### ### ### ### ### ### ###  \n",
    "    \n",
    "    \n",
    "    def random_path(self, min_len=10):\n",
    "        hp, hlab, op = [], [], []\n",
    "        hp.append(self.states[0])\n",
    "        hlab.append(self.labels[0])\n",
    "        op=[None]\n",
    "        cs = 0\n",
    "        i = 0\n",
    "        while i< min_len:\n",
    "            new_state = np.random.choice(range(1,self.n_states),1,p=self.a[cs][1:])[0]\n",
    "            if self.states[new_state] != self.states[-1]:\n",
    "                cs = new_state\n",
    "                hp.append(self.states[cs])\n",
    "                hlab.append(self.labels[cs])\n",
    "                symb = np.random.choice(range(self.n_symb),1,p=self.e[cs])[0]\n",
    "                op.append(self.symbols[symb])\n",
    "                i +=1\n",
    "        while self.states[new_state] != self.states[-1]:\n",
    "            new_state = np.random.choice(range(1,self.n_states),1,p=self.a[cs][1:])[0]\n",
    "            if self.states[new_state] != self.states[-1]:\n",
    "                cs = new_state\n",
    "                hp.append(self.states[cs])\n",
    "                hlab.append(self.labels[cs])\n",
    "                symb = np.random.choice(range(self.n_symb),1,p=self.e[cs])[0]\n",
    "                op.append(self.symbols[symb])\n",
    "        return hp, hlab, op\n",
    "\n",
    "    ### ### ### ### ### ### ### ###\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "transitions = np.array([[0, 0.30,   0,   0, 0.7,   0],\n",
    "                       [0,    0, 1.0,   0,   0,   0],\n",
    "                       [0,    0, 0.05, 0.90,  0.05,   0],\n",
    "                       [0,    0,   0, 0.6, 0.3, 0.1], \n",
    "                       [0,    0.1,   0, 0, 0.8, 0.1],\n",
    "                       [0,    0,   0,   0,   0,   0]])\n",
    "\n",
    "emissions = np.array([ [0, 0], [0.2, 0.8], [0.2, 0.8], [0.2, 0.8], [0.5, 0.5], [0, 0] ])\n",
    "\n",
    "hmm = base_HMM([\"begin\",\"l1\",\"l2\",\"l3\",\"f1\",\"end\"],\n",
    "               [\"-\",\"L\",\"L\",\"L\",\"F\",\"-\"], [\"H\",\"T\"],\n",
    "               a=transitions, \n",
    "               e=emissions )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that creates training or testing set \n",
    "def mkset(N,hmm, ml):\n",
    "    X, y =[], []\n",
    "    for n in range(N):\n",
    "        states, state_labels, observed = hmm.random_path(ml)\n",
    "        X.append(\"\".join(observed[1:-1])) \n",
    "        y.append(\"\".join(state_labels[1:-1]))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing class functions #\n",
    "In this last part, we test class function we some training set that we can generate through mkset function .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHTTTTTHHHTTTHHH\n",
      "FFFFLLLLFFFFFLLL\n"
     ]
    }
   ],
   "source": [
    "Ntrain = 10  # set this eg. 100 or 1000\n",
    "Ntest = 5   # set this eg. 100\n",
    "min_seq_len = 4 # set this 10 or 50 or 100\n",
    "X_train, y_train = mkset(Ntrain,hmm, min_seq_len) \n",
    "X_test, y_test = mkset(Ntest,hmm, min_seq_len) \n",
    "\n",
    "#print(X_train, y_train)\n",
    "\n",
    "#print(X_test, y_test)\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and backward matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.         0.05263158 0.94736842 0.         0.        ]\n",
      " [0.         0.         0.00425532 0.99574468 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.         0.05263158 0.94736842 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(hmm.forward(X_train[0],y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.50699143 0.30594497 0.1870636  0.         0.        ]\n",
      " [0.         0.48999775 0.3158013  0.19420094 0.         0.        ]\n",
      " [0.         0.09950249 0.54228856 0.35820896 0.         0.        ]\n",
      " [0.         0.         0.14285714 0.85714286 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.48780488 0.31707317 0.19512195 0.         0.        ]\n",
      " [0.         0.         0.6        0.4        0.         0.        ]\n",
      " [0.         0.         0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(hmm.backward(X_train[0],y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding algorithms \n",
    "\n",
    "These algorithms find the most probable state of the hidden variables in the model given the observations.\n",
    "\n",
    "- Viterbi \n",
    "- A posteriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    c=0\n",
    "    m=len(y_pred)\n",
    "    for i in range (m):\n",
    "        if y_pred[i]==y[i]:\n",
    "            c+=1\n",
    "    return c/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden path for Viterbi algorithm is ['F', 'F', 'F', 'L', 'L', 'L', 'L', 'L']\n",
      "Accuracy for Viterbi algorithm is 0.875\n"
     ]
    }
   ],
   "source": [
    "Predict=hmm.viterbi(X_train[0])[1]\n",
    "\n",
    "acc=accuracy(Predict, y_train[0])\n",
    "\n",
    "print(\"Hidden path for Viterbi algorithm is \" + str(Predict))\n",
    "print(\"Accuracy for Viterbi algorithm is \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden path for a posteriori algorithm is ['F', 'F', 'L', 'L', 'L', 'L', 'L', 'L']\n",
      "Accuracy for a posteriori algorithm is 1.0\n"
     ]
    }
   ],
   "source": [
    "hmm.posteriori(X_train[0],y_train[0])\n",
    "\n",
    "Predict=hmm.posteriori(X_train[0], y_train[0])[1]\n",
    "\n",
    "acc=accuracy(Predict, y_train[0])\n",
    "\n",
    "print(\"Hidden path for a posteriori algorithm is \" + str(Predict))\n",
    "print(\"Accuracy for a posteriori algorithm is \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baum - Welch algorithm\n",
    "doesn't work.\n",
    "\n",
    "The idea is to \n",
    "- generate random matrices a and e\n",
    "- compute Forward and backward\n",
    "- compute gamma and csi matrices in order to create\n",
    "- matrices a  and e with a correction\n",
    "- reiterate this process using last found a and e\n",
    "\n",
    "In this way given X train and Y_train, we should get matrices of transition and emission.\n",
    "This doesn't happen in my code: function outcome does not really make sense to me (not normalized for exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , 0.        , 0.07106037,\n",
       "         0.        ],\n",
       "        [0.        , 0.03096929, 0.01347873, 0.02212412, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.01755207, 0.01239235, 0.00426059, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.01852467, 0.01164643, 0.00675649, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.06887662, 0.02940199, 0.01369551, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.        , 0.        ],\n",
       "        [0.        , 0.45003242],\n",
       "        [0.        , 0.23191105],\n",
       "        [0.        , 0.18347252],\n",
       "        [1.        , 0.        ],\n",
       "        [0.        , 0.        ]]))"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.baum_welch(\"HTTT\", \"FLLL\", n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
